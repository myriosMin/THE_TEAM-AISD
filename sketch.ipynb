{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.read_csv(\"data/01_raw/olist_geolocation_dataset.csv\")\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(geo['geolocation_lng'], geo['geolocation_lat'], s=0.01, alpha=0.5)\n",
    "plt.title('Geolocation Points Across Brazil')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_range = (\n",
    "    geo.groupby(\"geolocation_zip_code_prefix\")\n",
    "    .agg({\n",
    "        \"geolocation_lat\": [\"min\", \"max\", \"std\"],\n",
    "        \"geolocation_lng\": [\"min\", \"max\", \"std\"],\n",
    "        \"geolocation_city\": \"nunique\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# Flatten column names\n",
    "geo_range.columns = ['lat_min', 'lat_max', 'lat_std', 'lng_min', 'lng_max', 'lng_std', 'n_cities']\n",
    "geo_range[\"lat_range\"] = geo_range[\"lat_max\"] - geo_range[\"lat_min\"]\n",
    "geo_range[\"lng_range\"] = geo_range[\"lng_max\"] - geo_range[\"lng_min\"]\n",
    "geo_range = geo_range.reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(geo_range[\"lat_range\"], bins=100)\n",
    "plt.title(\"Latitude Range per Zip Code Prefix\")\n",
    "plt.xlabel(\"Latitude Range (degrees)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 5)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(geo_range[\"lng_range\"], bins=100)\n",
    "plt.title(\"Longitude Range per Zip Code Prefix\")\n",
    "plt.xlabel(\"Longitude Range (degrees)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_zips = geo_range[\n",
    "    (geo_range[\"lat_range\"] > 0.5) | (geo_range[\"lng_range\"] > 0.5)\n",
    "]\n",
    "print(f\"{len(noisy_zips)} zip prefixes have high spatial variance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_geo = geo[~geo[\"geolocation_zip_code_prefix\"].isin(noisy_zips[\"geolocation_zip_code_prefix\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Brazil's bounding box\n",
    "valid_lat_range = (-33.75116944, 5.27438888)\n",
    "valid_lng_range = (-73.98283055, -34.79314722)\n",
    "\n",
    "# Apply filtering\n",
    "geo_clipped = clean_geo[\n",
    "    (clean_geo[\"geolocation_lat\"].between(*valid_lat_range)) &\n",
    "    (clean_geo[\"geolocation_lng\"].between(*valid_lng_range))\n",
    "]\n",
    "\n",
    "print(f\"Original: {len(clean_geo):,} | Clipped: {len(geo_clipped):,} | Removed: {len(clean_geo) - len(geo_clipped):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_clipped.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_parquet(\"data/02_intermediate/clean_orders.parquet\")\n",
    "customers = pd.read_parquet(\"data/02_intermediate/clean_customers.parquet\")\n",
    "order_items = pd.read_parquet(\"data/02_intermediate/clean_items.parquet\")\n",
    "sellers = pd.read_parquet(\"data/02_intermediate/clean_sellers.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_centroids = (\n",
    "    geo_clipped\n",
    "    .groupby(\"geolocation_zip_code_prefix\")[[\"geolocation_lat\", \"geolocation_lng\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "customers[\"customer_zip_code_prefix\"] = customers[\"customer_zip_code_prefix\"].astype(str)\n",
    "sellers[\"seller_zip_code_prefix\"] = sellers[\"seller_zip_code_prefix\"].astype(str)\n",
    "geo_centroids[\"geolocation_zip_code_prefix\"] = geo_centroids[\"geolocation_zip_code_prefix\"].astype(str)\n",
    "\n",
    "# Rename columns for clarity before merge\n",
    "customer_coords = geo_centroids.rename(columns={\n",
    "    \"geolocation_zip_code_prefix\": \"customer_zip_code_prefix\",\n",
    "    \"geolocation_lat\": \"customer_lat\",\n",
    "    \"geolocation_lng\": \"customer_lng\"\n",
    "})\n",
    "\n",
    "seller_coords = geo_centroids.rename(columns={\n",
    "    \"geolocation_zip_code_prefix\": \"seller_zip_code_prefix\",\n",
    "    \"geolocation_lat\": \"seller_lat\",\n",
    "    \"geolocation_lng\": \"seller_lng\"\n",
    "})\n",
    "\n",
    "# Step 1: Merge orders with customers to get customer zip prefix\n",
    "orders_customers = orders.merge(\n",
    "    customers[[\"customer_id\", \"customer_zip_code_prefix\"]],\n",
    "    on=\"customer_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Step 2: Merge order_items with sellers to get seller zip prefix\n",
    "order_items_sellers = order_items.merge(\n",
    "    sellers[[\"seller_id\", \"seller_zip_code_prefix\"]],\n",
    "    on=\"seller_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Step 3: Merge the two on order_id to get both customer and seller zip prefixes\n",
    "transactions = order_items_sellers.merge(\n",
    "    orders_customers[[\"order_id\", \"customer_zip_code_prefix\"]],\n",
    "    on=\"order_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "transactions[\"customer_zip_code_prefix\"] = transactions[\"customer_zip_code_prefix\"].astype(str)\n",
    "transactions[\"seller_zip_code_prefix\"] = transactions[\"seller_zip_code_prefix\"].astype(str)\n",
    "\n",
    "merged = transactions \\\n",
    "    .merge(customer_coords, on=\"customer_zip_code_prefix\", how=\"left\") \\\n",
    "    .merge(seller_coords, on=\"seller_zip_code_prefix\", how=\"left\")\n",
    "    \n",
    "def haversine_distance(lat1, lng1, lat2, lng2):\n",
    "    R = 6371  # Earth radius in km\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, [lat1, lng1, lat2, lng2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlng = lng2 - lng1\n",
    "\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlng/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "merged[\"distance_km\"] = haversine_distance(\n",
    "    merged[\"customer_lat\"],\n",
    "    merged[\"customer_lng\"],\n",
    "    merged[\"seller_lat\"],\n",
    "    merged[\"seller_lng\"]\n",
    ")\n",
    "\n",
    "merged = merged.dropna(subset=[\"distance_km\"])\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# File path to the src directory for both linux and windows\n",
    "# workaround for the issue of relative imports in Jupyter notebooks to import modules from src without using the full path\n",
    "src_path = os.path.abspath(\"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    \n",
    "# Rerun this cell after making changes to the utils module\n",
    "from the_team.utils import etl, viz\n",
    "import importlib\n",
    "importlib.reload(etl)\n",
    "importlib.reload(viz)\n",
    "\n",
    "# Set custom plot style for consistency\n",
    "viz.set_plot_style()\n",
    "\n",
    "viz.plot_numeric_distribution(merged[['distance_km']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
